# Experiment on Azerbaijani->English translations using the
# TED-Talks dataset.

include "../../common.conf"

data {
  dataset: "ted_talks"

  train-batch-size: 1024
  infer-batch-size: 128
  eval-batch-size: 128

  include "../../vocabularies/bpe_5k.conf"
}

model {
  parameters {
    word-embeddings-size: 128

    include "../../parameters/pairwise.conf"
  }

  include "../../models/transformer/transformer_tiny.conf"
}

training {
  both-directions: false
  languages: "az:en"
  use-identity-translations: true
  checkpoint-steps: 1000
  summary-steps: 100
}

inference {
  beam-width: 10
  length-penalty: 0.6
  max-decoding-length-factor: 2.0
}

evaluation {
  datasets: "dev:1.00,test:1.00"
  languages: "az:en"
}
