# Experiment on Azerbaijani->English translations using the
# TED-Talks dataset.

include "../../common.conf"

data {
  dataset: "ted_talks"

  train-batch-size: 128
  infer-batch-size: 32
  eval-batch-size: 32

  include "../../vocabularies/bpe_5k.conf"
}

model {
  languages: "az:en,be:en,gl:en"
  eval-languages: "az:en,be:en,gl:en"
  both-directions: true

  parameters {
    word-embeddings-size: 128

    include "../../parameters/contextual_language.conf"
  }

  include "../../models/rnn/bi_rnn_small.conf"

  training {
    use-identity-translations: true
    checkpoint-steps: 1000
    summary-steps: 100
  }

  inference {
    beam-width: 10
    length-penalty: 0.6
    max-decoding-length-factor: 2.0
  }

  evaluation {
    datasets: "dev:1.00,test:1.00"
  }
}
