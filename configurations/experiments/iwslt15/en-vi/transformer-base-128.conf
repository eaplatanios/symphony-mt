include "base.conf"

data {
  train-batch-size: 512
  infer-batch-size: 128
  eval-batch-size: 128

  include "../../../vocabularies/word-count-20k.conf"
}

model {
  name: "transformer-base-128"

  parameters {
    word-embeddings-size: 128

    include "../../../parameters/pairwise.conf"
  }

  include "../../../models/transformer/transformer-base.conf"
}

training {
  checkpoint-frequency: 5000

  optimization {
    max-grad-norm: 10.0
  }
}

inference {
  beam-width: 4
  length-penalty: 0.6
  max-decoding-length-factor: 2.0
}

evaluation {
  frequency: 5000
}
