# Small bi-directional RNN model.

encoder {
  type: "bi-rnn"
  num-units: ${model.parameters.word-embeddings-size}
  num-layers: 2
  residual: true
  dropout: 0.2

  cell {
    type: "lstm"
    activation: "tanh"
    forget-bias: 1.0
  }
}

decoder {
  type: "rnn"
  num-units: ${model.parameters.word-embeddings-size}
  num-layers: 2
  residual: true
  dropout: 0.2
  use-attention: true

  cell {
    type: "lstm"
    activation: "tanh"
    forget-bias: 1.0
  }
}

training {
  optimization {
    optimizer: "amsgrad"
    learning-rate: 0.001
    max-grad-norm: 100.0
  }
}
