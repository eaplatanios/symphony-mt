# Base transformer model.

encoder {
  type: "transformer"
  num-units: ${model.parameters.word-embeddings-size}
  num-layers: 6
  use-self-attention-proximity-bias: false
  post-position-embeddings-dropout: 0.1
  attention-keys-depth: 64
  attention-values-depth: 64
  attention-num-heads: 8
  dot-product-attention-dropout: 0.1
  feed-forward-filter-size: 2048
  feed-forward-relu-dropout: 0.1
}

decoder {
  type: "transformer"
  num-units: ${model.parameters.word-embeddings-size}
  num-layers: 6
  use-self-attention-proximity-bias: false
  post-position-embeddings-dropout: 0.1
  attention-keys-depth: 64
  attention-values-depth: 64
  attention-num-heads: 8
  dot-product-attention-dropout: 0.1
  feed-forward-filter-size: 2048
  feed-forward-relu-dropout: 0.1
  output-layer: "projection-to-words"
}
