# Base transformer model.

encoder {
  type: "transformer"
  num-units: ${model.parameters.word-embeddings-size}
  num-layers: 4
  use-self-attention-proximity-bias: false
  post-position-embeddings-dropout: 0.1
  attention-keys-depth: ${model.parameters.word-embeddings-size}
  attention-values-depth: ${model.parameters.word-embeddings-size}
  attention-num-heads: 4
  dot-product-attention-dropout: 0.1
  feed-forward-filter-size: 512
  feed-forward-relu-dropout: 0.1
}

decoder {
  type: "transformer"
  num-units: ${model.parameters.word-embeddings-size}
  num-layers: 4
  use-self-attention-proximity-bias: false
  post-position-embeddings-dropout: 0.1
  attention-keys-depth: ${model.parameters.word-embeddings-size}
  attention-values-depth: ${model.parameters.word-embeddings-size}
  attention-num-heads: 4
  dot-product-attention-dropout: 0.1
  feed-forward-filter-size: 512
  feed-forward-relu-dropout: 0.1
  output-layer: "projection-to-words"
}
